{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da59b553-10e7-43a3-beca-fa8ce38641d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe0608b-1491-40c3-9ad4-a3402ca38ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6171f327-14db-4335-9c76-e38f1c0d11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variable\n",
    "credentials_file = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "531acedb-4dec-4f0a-a0d3-1c70f3ad6892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset sharedgcpproject.headline_dataset\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "dataset_id = \"{}.headline_dataset\".format(client.project)\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"US\"\n",
    "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f895992-cb89-49b5-a7c3-bf23ac53b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUpload = pd.DataFrame()\n",
    "def scraper(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    if url[24:30] == \"search\":\n",
    "        blocks = soup.find_all(\"div\", class_=\"xrnccd\")\n",
    "    elif url[24:30] == \"topics\":\n",
    "        blocks = soup.find_all(\"c-wiz\", class_=\"PO9Zff Ccj79 kUVvS\")\n",
    "    \n",
    "    HL = []\n",
    "    DATE = []\n",
    "    TIME = []\n",
    "    LINK = []\n",
    "    PB = []\n",
    "    for i in range(len(blocks)):\n",
    "        if url[24:30] == \"search\":\n",
    "            headline = blocks[i].find(\"a\", class_=\"DY5T1d RZIKme\").get_text()\n",
    "            link = blocks[i].find(\"a\", class_=\"DY5T1d RZIKme\").get(\"href\")\n",
    "            date_and_time = blocks[i].find(\"time\", class_=\"WW6dff uQIVzc Sksgp slhocf\")\n",
    "            publisher = soup.find(\"a\", class_=\"wEwyrc AVN2gc WfKKme\").get_text()\n",
    "        elif url[24:30] == \"topics\":\n",
    "            headline = blocks[i].find(\"a\", class_=\"WwrzSb\").get(\"aria-label\")\n",
    "            link = blocks[i].find(\"a\", class_=\"WwrzSb\").get(\"href\")\n",
    "            date_and_time = blocks[i].find(\"time\", class_=\"hvbAAd\")\n",
    "            publisher = soup.find(\"span\", class_=\"vr1PYe\").get_text()\n",
    "\n",
    "        HL.append(headline)\n",
    "        LINK.append(\"https://news.google.com/\"+link)\n",
    "        PB.append(publisher)\n",
    "        DATE.append(re.match(\"^([^T]+)\", date_and_time.get(\"datetime\")).group(0))\n",
    "        TIME.append(re.search(r'(?<=T)(.*)(?=Z)', date_and_time.get(\"datetime\")).group(1))\n",
    "\n",
    "    if url[24:30] == \"search\":\n",
    "        search_data = pd.DataFrame({\"Headline\": HL, \"Date\": DATE, \"Time\": TIME, \"link\": LINK, \"Publisher\": PB})\n",
    "        # still need to adjust the file name according to the url\n",
    "        search_data.to_csv(str(datetime.today().date())+\"_DSdata.csv\")\n",
    "        print(str(len(search_data))+\" headlines scraped from search!\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        data = pd.DataFrame({\"Headline\": HL, \"Date\": DATE, \"Time\": TIME, \"link\": LINK, \"Publisher\": PB})\n",
    "        today = str(datetime.today().date())\n",
    "        data.to_csv(today+\"_USdata.csv\") \n",
    "        print(str(len(data))+\" headlines scraped from topics!\")\n",
    "    \n",
    "    \n",
    "    table_id = 'headline_dataset.new_table'\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(schema=[bigquery.SchemaField(\"Headline\", \"STRING\"),])\n",
    "    job = client.load_table_from_dataframe(search_data, table_id, job_config=job_config)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f295d8f0-4a3d-4efa-b91f-3bf401b877f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 headlines scraped from search!\n"
     ]
    }
   ],
   "source": [
    "# url for the US topic google news\n",
    "url = \"https://news.google.com/topics/CAAqIggKIhxDQkFTRHdvSkwyMHZNRGxqTjNjd0VnSmxiaWdBUAE?hl=en-US&gl=US&ceid=US%3Aen\"\n",
    "# url for the Data Science search results\n",
    "url = \"https://news.google.com/search?q=data%20science&hl=en-US&gl=US&ceid=US%3Aen\"\n",
    "\n",
    "scraper(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a258c418-74a4-41c2-a754-3a6205309203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4818ae1-42d3-4776-9b06-163a015c3b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
